Task 1. Create an Vertex Notebooks instance


Task 2. Download the challenge notebook


Task 3. Build and train your model locally in a Vertex notebook

def build_text_classifier(hparams, optimizer):
    """Define and compile a TensorFlow BERT sentiment classifier.
    Args:
      hparams(dict): A dictionary containing model training arguments.
    Returns:
      model(tf.keras.Model): A compiled TensorFlow model.
    """
    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')
    # TODO: Add a hub.KerasLayer for BERT text preprocessing using the hparams dict. 
    # Name the layer 'preprocessing' and store in the variable preprocessor.
    preprocessor = hub.KerasLayer(hparams['tfhub-bert-preprocessor'],
                                  name='preprocessing')
    
    encoder_inputs = preprocessor(text_input)
    encoder = hub.KerasLayer(hparams['tfhub-bert-encoder'],
                             name='BERT_encoder')
    # TODO: Add a trainable hub.KerasLayer for BERT text encoding using the hparams dict.
    # Name the layer 'BERT_encoder' and store in the variable encoder.

    outputs = encoder(encoder_inputs)
    # For the fine-tuning you are going to use the `pooled_output` array which represents 
    # each input sequence as a whole. The shape is [batch_size, H]. 
    # You can think of this as an embedding for the entire movie review.
    classifier = outputs['pooled_output']
    # Add dropout to prevent overfitting during model fine-tuning.
    classifier = tf.keras.layers.Dropout(hparams['dropout'], name='dropout')(classifier)
    classifier = tf.keras.layers.Dense(1, activation=None, name='classifier')(classifier)
    model = tf.keras.Model(text_input, classifier, name='bert-sentiment-classifier')
    
    loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)
    metrics = tf.metrics.BinaryAccuracy()    
    
    model.compile(optimizer=optimizer,
                  loss=loss,
                  metrics=metrics)    
    
    return model


HPARAMS.update({
    'model-dir': './bert-sentiment-classifier-local'
    # TODO: Save your BERT sentiment classifier locally. 
    # Hint: Save it to './bert-sentiment-classifier-local'. Note the key name in model.save().
    
})


Task 4. Use Cloud Build to build and submit your model container to Google Cloud Artifact Registry

!gcloud artifacts repositories create {ARTIFACT_REGISTRY} \
--repository-format=docker \
--location={REGION}

!gcloud builds submit {MODEL_DIR} --timeout=20m --config {MODEL_DIR}/cloudbuild.yaml


Task 5. Define a pipeline using the KFP SDK


Task 6. Query deployed model on Vertex Endpoint for online predictions

endpoint = vertexai.Endpoint(
	endpoint_name=ENDPOINT_NAME,
	project=PROJECT_ID,
	location=REGION
)




